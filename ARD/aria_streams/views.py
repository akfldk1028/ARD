from rest_framework import viewsets, status, permissions
from rest_framework.decorators import action, api_view
from rest_framework.response import Response
from rest_framework.views import APIView
from rest_framework.reverse import reverse
from django.http import HttpResponse
from django_filters.rest_framework import DjangoFilterBackend
from rest_framework.filters import SearchFilter, OrderingFilter
from django.utils import timezone
from django.db.models import Q, Count, Avg, Max, Min
from datetime import datetime, timedelta
import threading
import asyncio
import logging

from .models import (
    AriaSession, VRSStream, EyeGazeData, 
    HandTrackingData, SLAMTrajectoryData,
    SLAMPointCloud, AnalyticsResult, KafkaConsumerStatus,
    IMUData
)
from .raw_models import RawEyeGazeData, RawHandTrackingData, RawSlamTrajectoryData
from .serializers import (
    AriaSessionSerializer, VRSStreamSerializer, EyeGazeDataSerializer,
    HandTrackingDataSerializer, SLAMTrajectoryDataSerializer,
    SLAMPointCloudSerializer, AnalyticsResultSerializer, 
    KafkaConsumerStatusSerializer, StreamingControlSerializer,
    TestMessageSerializer, EyeGazeStreamingSerializer, HandTrackingStreamingSerializer,
    IMUDataSerializer
)
from .producers import AriaKafkaProducer
from .vrs_reader import VRSKafkaStreamer
from kafka import KafkaConsumer
import base64
import uuid
from projectaria_tools.core import mps

logger = logging.getLogger(__name__)

# ì „ì—­ ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ê´€ë¦¬
streaming_status = {
    'is_streaming': False,
    'current_streams': [],
    'last_started': None,
    'message_count': 0
}


class AriaSessionViewSet(viewsets.ModelViewSet):
    """
    Aria ì„¸ì…˜ ê´€ë¦¬ ViewSet
    - ì„¸ì…˜ ìƒì„±, ì¡°íšŒ, ìˆ˜ì •, ì‚­ì œ
    - ì„¸ì…˜ë³„ ìŠ¤íŠ¸ë¦¼ ë°ì´í„° í†µê³„
    """
    queryset = AriaSession.objects.all()
    serializer_class = AriaSessionSerializer
    filter_backends = [DjangoFilterBackend, SearchFilter, OrderingFilter]
    filterset_fields = ['status', 'device_serial']
    search_fields = ['session_id', 'device_serial']
    ordering_fields = ['started_at', 'ended_at']
    ordering = ['-started_at']
    
    def get_queryset(self):
        """ì»¤ìŠ¤í…€ ì¿¼ë¦¬ì…‹ - prefetchë¡œ ì„±ëŠ¥ ìµœì í™”"""
        return super().get_queryset().prefetch_related(
            'vrs_streams', 'eye_gaze_data', 'hand_tracking_data',
            'slam_trajectory_data', 'slam_point_clouds', 'analytics_results'
        )
    
    @action(detail=True, methods=['post'])
    def end_session(self, request, pk=None):
        """ì„¸ì…˜ ì¢…ë£Œ"""
        session = self.get_object()
        if session.status == 'COMPLETED':
            return Response(
                {'detail': 'ì´ë¯¸ ì™„ë£Œëœ ì„¸ì…˜ì…ë‹ˆë‹¤.'}, 
                status=status.HTTP_400_BAD_REQUEST
            )
        
        session.ended_at = timezone.now()
        session.status = 'COMPLETED'
        session.save()
        
        return Response({
            'detail': 'ì„¸ì…˜ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
            'ended_at': session.ended_at,
            'duration': (session.ended_at - session.started_at).total_seconds()
        })
    
    @action(detail=True, methods=['get'])
    def statistics(self, request, pk=None):
        """ì„¸ì…˜ë³„ ìƒì„¸ í†µê³„"""
        session = self.get_object()
        
        # ì‹œê°„ëŒ€ë³„ ë°ì´í„° ë¶„í¬
        time_ranges = []
        current = session.started_at
        end_time = session.ended_at or timezone.now()
        
        while current < end_time:
            next_time = current + timedelta(minutes=10)
            range_data = {
                'start': current,
                'end': min(next_time, end_time),
                'vrs_count': session.vrs_streams.filter(
                    timestamp__range=(current, next_time)
                ).count(),
                'gaze_count': session.eye_gaze_data.filter(
                    timestamp__range=(current, next_time)
                ).count()
            }
            time_ranges.append(range_data)
            current = next_time
        
        return Response({
            'session_id': session.session_id,
            'total_duration': (end_time - session.started_at).total_seconds(),
            'time_ranges': time_ranges,
            'stream_distribution': {
                'vrs_streams': session.vrs_streams.values('stream_name').annotate(
                    count=Count('id')
                ),
                'gaze_types': session.eye_gaze_data.values('gaze_type').annotate(
                    count=Count('id')
                )
            }
        })


class VRSStreamViewSet(viewsets.ReadOnlyModelViewSet):
    """
    VRS ìŠ¤íŠ¸ë¦¼ ë°ì´í„° ViewSet (ì½ê¸° ì „ìš©)
    - ìŠ¤íŠ¸ë¦¼ë³„ í•„í„°ë§ ë° ê²€ìƒ‰
    - ì‹œê°„ ë²”ìœ„ í•„í„°ë§
    """
    queryset = VRSStream.objects.all()
    serializer_class = VRSStreamSerializer
    filter_backends = [DjangoFilterBackend, SearchFilter, OrderingFilter]
    filterset_fields = ['session', 'stream_name', 'pixel_format']
    search_fields = ['stream_name', 'session__session_id']
    ordering_fields = ['timestamp', 'device_timestamp_ns', 'frame_index']
    ordering = ['-timestamp']
    
    def get_queryset(self):
        queryset = super().get_queryset().select_related('session')
        
        # ì‹œê°„ ë²”ìœ„ í•„í„°ë§
        start_time = self.request.query_params.get('start_time')
        end_time = self.request.query_params.get('end_time')
        
        if start_time:
            queryset = queryset.filter(timestamp__gte=start_time)
        if end_time:
            queryset = queryset.filter(timestamp__lte=end_time)
            
        return queryset
    
    @action(detail=False, methods=['get'])
    def stream_summary(self, request):
        """ìŠ¤íŠ¸ë¦¼ë³„ ìš”ì•½ í†µê³„"""
        summary = self.get_queryset().values('stream_name').annotate(
            total_frames=Count('id'),
            latest_frame=Max('timestamp'),
            avg_fps=Count('id') / (
                (Max('timestamp') - Min('timestamp')).total_seconds() or 1
            )
        ).order_by('-total_frames')
        
        return Response(summary)


class IMUDataViewSet(viewsets.ReadOnlyModelViewSet):
    """
    IMU ë°ì´í„° ViewSet (ì½ê¸° ì „ìš©)
    - IMU íƒ€ì…ë³„ í•„í„°ë§ (left/right)
    - ê°€ì†ë„/ìì´ë¡œ ë°ì´í„° ì¡°íšŒ
    - ì‹¤ì‹œê°„ ëª¨ì…˜ ë¶„ì„
    """
    queryset = IMUData.objects.all()
    serializer_class = IMUDataSerializer
    filter_backends = [DjangoFilterBackend, SearchFilter, OrderingFilter]
    filterset_fields = ['session', 'imu_type', 'imu_stream_id']
    search_fields = ['session__session_id', 'imu_type']
    ordering_fields = ['timestamp', 'device_timestamp_ns']
    ordering = ['-timestamp']
    
    def get_queryset(self):
        queryset = super().get_queryset().select_related('session')
        
        # ì‹œê°„ ë²”ìœ„ í•„í„°ë§
        start_time = self.request.query_params.get('start_time')
        end_time = self.request.query_params.get('end_time')
        
        if start_time:
            queryset = queryset.filter(timestamp__gte=start_time)
        if end_time:
            queryset = queryset.filter(timestamp__lte=end_time)
            
        # ê°€ì†ë„/ìì´ë¡œ ì„ê³„ê°’ í•„í„°ë§
        min_accel = self.request.query_params.get('min_acceleration')
        min_gyro = self.request.query_params.get('min_angular_velocity')
        
        if min_accel:
            # SQLì—ì„œ ë²¡í„° í¬ê¸° ê³„ì‚°
            queryset = queryset.extra(
                where=["SQRT(accel_x*accel_x + accel_y*accel_y + accel_z*accel_z) >= %s"],
                params=[float(min_accel)]
            )
        if min_gyro:
            queryset = queryset.extra(
                where=["SQRT(gyro_x*gyro_x + gyro_y*gyro_y + gyro_z*gyro_z) >= %s"],
                params=[float(min_gyro)]
            )
            
        return queryset
    
    @action(detail=False, methods=['get'])
    def motion_analysis(self, request):
        """IMU ëª¨ì…˜ ë¶„ì„ - ê°€ì†ë„/ìì´ë¡œ í†µê³„"""
        session_id = request.query_params.get('session')
        imu_type = request.query_params.get('imu_type', 'left')
        
        queryset = self.get_queryset()
        if session_id:
            queryset = queryset.filter(session_id=session_id)
        
        queryset = queryset.filter(imu_type=imu_type)
        
        if not queryset.exists():
            return Response({'detail': 'No IMU data found'}, status=404)
        
        # í†µê³„ ê³„ì‚°
        stats = queryset.aggregate(
            accel_x_avg=Avg('accel_x'),
            accel_y_avg=Avg('accel_y'),
            accel_z_avg=Avg('accel_z'),
            accel_x_max=Max('accel_x'),
            accel_y_max=Max('accel_y'),
            accel_z_max=Max('accel_z'),
            gyro_x_avg=Avg('gyro_x'),
            gyro_y_avg=Avg('gyro_y'),
            gyro_z_avg=Avg('gyro_z'),
            gyro_x_max=Max('gyro_x'),
            gyro_y_max=Max('gyro_y'),
            gyro_z_max=Max('gyro_z'),
            temp_avg=Avg('temperature_c'),
            temp_max=Max('temperature_c'),
            temp_min=Min('temperature_c'),
            sample_count=Count('id')
        )
        
        return Response({
            'imu_type': imu_type,
            'session': session_id,
            'sample_count': stats['sample_count'],
            'acceleration_stats': {
                'x_avg': round(stats['accel_x_avg'], 4),
                'y_avg': round(stats['accel_y_avg'], 4), 
                'z_avg': round(stats['accel_z_avg'], 4),
                'x_max': round(stats['accel_x_max'], 4),
                'y_max': round(stats['accel_y_max'], 4),
                'z_max': round(stats['accel_z_max'], 4)
            },
            'gyroscope_stats': {
                'x_avg': round(stats['gyro_x_avg'], 4),
                'y_avg': round(stats['gyro_y_avg'], 4),
                'z_avg': round(stats['gyro_z_avg'], 4),
                'x_max': round(stats['gyro_x_max'], 4),
                'y_max': round(stats['gyro_y_max'], 4),
                'z_max': round(stats['gyro_z_max'], 4)
            },
            'temperature_stats': {
                'avg': round(stats['temp_avg'], 2) if stats['temp_avg'] else None,
                'max': round(stats['temp_max'], 2) if stats['temp_max'] else None,
                'min': round(stats['temp_min'], 2) if stats['temp_min'] else None
            }
        })


class EyeGazeDataViewSet(viewsets.ReadOnlyModelViewSet):
    """
    Eye Gaze ë°ì´í„° ViewSet
    - Gaze íƒ€ì…ë³„ í•„í„°ë§
    - ì‹œê°„ ë²”ìœ„ ë° ì •í™•ë„ í•„í„°ë§
    """
    queryset = EyeGazeData.objects.all()
    serializer_class = EyeGazeDataSerializer
    filter_backends = [DjangoFilterBackend, SearchFilter, OrderingFilter]
    filterset_fields = ['session', 'gaze_type']
    ordering_fields = ['timestamp', 'device_timestamp_ns', 'confidence']
    ordering = ['-timestamp']
    
    def get_queryset(self):
        queryset = super().get_queryset().select_related('session')
        
        # ì •í™•ë„ í•„í„°ë§
        min_confidence = self.request.query_params.get('min_confidence')
        if min_confidence:
            queryset = queryset.filter(confidence__gte=float(min_confidence))
            
        # ê¹Šì´ ë²”ìœ„ í•„í„°ë§
        min_depth = self.request.query_params.get('min_depth')
        max_depth = self.request.query_params.get('max_depth')
        
        if min_depth:
            queryset = queryset.filter(depth_m__gte=float(min_depth))
        if max_depth:
            queryset = queryset.filter(depth_m__lte=float(max_depth))
            
        return queryset
    
    @action(detail=False, methods=['get'])
    def gaze_heatmap(self, request):
        """ì‹œì„  íˆíŠ¸ë§µ ë°ì´í„°"""
        session_id = request.query_params.get('session')
        gaze_type = request.query_params.get('gaze_type', 'general')
        
        queryset = self.get_queryset()
        if session_id:
            queryset = queryset.filter(session_id=session_id)
        
        queryset = queryset.filter(gaze_type=gaze_type)
        
        # ì‹œì„  ë°©í–¥ ë°ì´í„° ì§‘ê³„
        gaze_data = []
        for gaze in queryset[:1000]:  # ìµœëŒ€ 1000ê°œ ìƒ˜í”Œ
            gaze_data.append({
                'yaw': gaze.yaw,
                'pitch': gaze.pitch,
                'depth': gaze.depth_m,
                'timestamp': gaze.timestamp
            })
        
        return Response({
            'gaze_type': gaze_type,
            'total_samples': len(gaze_data),
            'gaze_data': gaze_data
        })


class HandTrackingDataViewSet(viewsets.ReadOnlyModelViewSet):
    """
    Hand Tracking ë°ì´í„° ViewSet
    - ì† ì¡´ì¬ ì—¬ë¶€ í•„í„°ë§
    - ëœë“œë§ˆí¬ ë°ì´í„° ì¡°íšŒ
    """
    queryset = HandTrackingData.objects.all()
    serializer_class = HandTrackingDataSerializer
    filter_backends = [DjangoFilterBackend, OrderingFilter]
    filterset_fields = ['session']
    ordering_fields = ['timestamp', 'device_timestamp_ns']
    ordering = ['-timestamp']
    
    def get_queryset(self):
        queryset = super().get_queryset().select_related('session')
        
        # ì† ì¡´ì¬ í•„í„°ë§
        has_left = self.request.query_params.get('has_left_hand')
        has_right = self.request.query_params.get('has_right_hand')
        
        if has_left == 'true':
            queryset = queryset.filter(left_hand_landmarks__isnull=False)
        elif has_left == 'false':
            queryset = queryset.filter(left_hand_landmarks__isnull=True)
            
        if has_right == 'true':
            queryset = queryset.filter(right_hand_landmarks__isnull=False)
        elif has_right == 'false':
            queryset = queryset.filter(right_hand_landmarks__isnull=True)
            
        return queryset
    
    @action(detail=False, methods=['get'])
    def hand_statistics(self, request):
        """ì† ì¶”ì  í†µê³„"""
        queryset = self.get_queryset()
        
        stats = {
            'total_frames': queryset.count(),
            'left_hand_detected': queryset.filter(
                left_hand_landmarks__isnull=False
            ).count(),
            'right_hand_detected': queryset.filter(
                right_hand_landmarks__isnull=False
            ).count(),
            'both_hands_detected': queryset.filter(
                left_hand_landmarks__isnull=False,
                right_hand_landmarks__isnull=False
            ).count()
        }
        
        return Response(stats)


class SLAMTrajectoryDataViewSet(viewsets.ReadOnlyModelViewSet):
    """
    SLAM Trajectory ë°ì´í„° ViewSet
    - ìœ„ì¹˜ ê¸°ë°˜ í•„í„°ë§
    - ê²½ë¡œ ì¶”ì  ë° ë¶„ì„
    """
    queryset = SLAMTrajectoryData.objects.all()
    serializer_class = SLAMTrajectoryDataSerializer
    filter_backends = [DjangoFilterBackend, OrderingFilter]
    filterset_fields = ['session']
    ordering_fields = ['timestamp', 'device_timestamp_ns']
    ordering = ['-timestamp']
    
    def get_queryset(self):
        queryset = super().get_queryset().select_related('session')
        
        # ìœ„ì¹˜ ë²”ìœ„ í•„í„°ë§
        x_min = self.request.query_params.get('x_min')
        x_max = self.request.query_params.get('x_max')
        y_min = self.request.query_params.get('y_min')
        y_max = self.request.query_params.get('y_max')
        z_min = self.request.query_params.get('z_min')
        z_max = self.request.query_params.get('z_max')
        
        if x_min: queryset = queryset.filter(position_x__gte=float(x_min))
        if x_max: queryset = queryset.filter(position_x__lte=float(x_max))
        if y_min: queryset = queryset.filter(position_y__gte=float(y_min))
        if y_max: queryset = queryset.filter(position_y__lte=float(y_max))
        if z_min: queryset = queryset.filter(position_z__gte=float(z_min))
        if z_max: queryset = queryset.filter(position_z__lte=float(z_max))
        
        return queryset
    
    @action(detail=False, methods=['get'])
    def trajectory_path(self, request):
        """ê¶¤ì  ê²½ë¡œ ë°ì´í„°"""
        session_id = request.query_params.get('session')
        limit = int(request.query_params.get('limit', 1000))
        
        queryset = self.get_queryset()
        if session_id:
            queryset = queryset.filter(session_id=session_id)
        
        trajectory_points = []
        for point in queryset.order_by('device_timestamp_ns')[:limit]:
            trajectory_points.append({
                'timestamp': point.timestamp,
                'position': {
                    'x': point.position_x,
                    'y': point.position_y,
                    'z': point.position_z
                },
                'transform_matrix': point.transform_matrix
            })
        
        return Response({
            'total_points': len(trajectory_points),
            'trajectory': trajectory_points
        })


class StreamingControlView(APIView):
    """
    ìŠ¤íŠ¸ë¦¬ë° ì œì–´ í†µí•© View
    - VRS/MPS ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘/ì¤‘ì§€
    - ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ì¡°íšŒ
    - ì§ì ‘ DB ì €ì¥ (Kafka ìš°íšŒ)
    """
    
    def get(self, request):
        """ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ì¡°íšŒ"""
        return Response({
            'status': 'success',
            'data': streaming_status,
            'timestamp': datetime.utcnow().isoformat()
        })
    
    def post(self, request):
        """ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘"""
        serializer = StreamingControlSerializer(data=request.data)
        if not serializer.is_valid():
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
        if streaming_status['is_streaming']:
            return Response({
                'status': 'error',
                'message': 'ì´ë¯¸ ìŠ¤íŠ¸ë¦¬ë°ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.'
            }, status=status.HTTP_400_BAD_REQUEST)
        
        duration = serializer.validated_data['duration']
        stream_type = serializer.validated_data['stream_type']
        
        def start_streaming():
            try:
                vrs_file = "/app/ARD/data/mps_samples/sample.vrs"
                mps_data_path = "/app/ARD/data/mps_samples"
                
                streamer = VRSKafkaStreamer(vrs_file, mps_data_path)
                
                # ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ì—…ë°ì´íŠ¸
                streaming_status['is_streaming'] = True
                streaming_status['current_streams'] = ['vrs', 'mps'] if stream_type == 'all' else [stream_type]
                streaming_status['last_started'] = datetime.utcnow().isoformat()
                
                # ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                tasks = []
                if stream_type in ['vrs', 'all']:
                    tasks.append(streamer.stream_vrs_data(duration))
                if stream_type in ['mps', 'all']:
                    tasks.append(streamer.stream_mps_data(duration))
                
                async def run_tasks():
                    await asyncio.gather(*tasks)
                
                loop.run_until_complete(run_tasks())


                # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ ìƒíƒœ ë¦¬ì…‹
                streaming_status['is_streaming'] = False
                streaming_status['current_streams'] = []
                
                streamer.close()
                
            except Exception as e:
                streaming_status['is_streaming'] = False
                streaming_status['current_streams'] = []
                logger.error(f"VRS streaming error: {e}")
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
        thread = threading.Thread(target=start_streaming)
        thread.daemon = True
        thread.start()
        
        return Response({
            'status': 'success',
            'message': f'{stream_type} ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤.',
            'duration': duration,
            'stream_type': stream_type,
            'timestamp': datetime.utcnow().isoformat()
        })
    
    def delete(self, request):
        """ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€"""
        if not streaming_status['is_streaming']:
            return Response({
                'status': 'error',
                'message': 'ì§„í–‰ ì¤‘ì¸ ìŠ¤íŠ¸ë¦¬ë°ì´ ì—†ìŠµë‹ˆë‹¤.'
            }, status=status.HTTP_400_BAD_REQUEST)
        
        streaming_status['is_streaming'] = False
        streaming_status['current_streams'] = []
        
        return Response({
            'status': 'success',
            'message': 'ìŠ¤íŠ¸ë¦¬ë°ì´ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'timestamp': datetime.utcnow().isoformat()
        })


class DirectMPSImportView(APIView):
    """
    MPS ë°ì´í„° ì§ì ‘ ì„í¬íŠ¸ View (Kafka ìš°íšŒ)
    - Eye Gaze, Hand Tracking, SLAM ë°ì´í„°ë¥¼ Django DBì— ì§ì ‘ ì €ì¥
    - Kafka ì—°ê²° ë¬¸ì œ í•´ê²°ìš©
    """
    
    def post(self, request):
        """MPS ë°ì´í„° ì§ì ‘ ì„í¬íŠ¸ ì‹¤í–‰"""
        try:
            # 1. ê¸°ì¡´ MPS ì„¸ì…˜ ì‚­ì œ
            deleted_count = AriaSession.objects.filter(session_id__contains='mps').delete()
            
            # 2. ìƒˆ ì„¸ì…˜ ìƒì„±
            session = AriaSession.objects.create(
                session_id='mps-direct-view',
                session_uid=uuid.uuid4(),
                device_serial='aria-view-device',
                status='COMPLETED',
                metadata={
                    'source': 'views_direct_import',
                    'method': 'DirectMPSImportView',
                    'bypass_kafka': True,
                    'import_time': datetime.utcnow().isoformat()
                }
            )
            
            # 3. Eye Gaze ë°ì´í„° ì„í¬íŠ¸ (ì¼ë°˜ + Raw)
            eye_gaze_count = self._import_eye_gaze_to_db(session)
            raw_eye_gaze_count = self._import_raw_eye_gaze_to_db(session)
            
            # 4. SLAM ë°ì´í„° ì„í¬íŠ¸ (ì¼ë°˜ + Raw)
            slam_count = self._import_slam_to_db(session)
            raw_slam_count = self._import_raw_slam_to_db(session)
            
            return Response({
                'status': 'success',
                'message': 'MPS ë°ì´í„° ì§ì ‘ ì„í¬íŠ¸ ì™„ë£Œ',
                'data': {
                    'session_id': session.session_id,
                    'processed_data': {
                        'eye_gaze_count': eye_gaze_count,
                        'slam_count': slam_count
                    },
                    'raw_data': {
                        'raw_eye_gaze_count': raw_eye_gaze_count,
                        'raw_slam_count': raw_slam_count
                    },
                    'total_count': eye_gaze_count + slam_count + raw_eye_gaze_count + raw_slam_count,
                    'deleted_old_sessions': deleted_count[0] if deleted_count else 0
                },
                'test_urls': {
                    'processed_apis': {
                        'sessions': '/api/v1/aria/api/sessions/',
                        'eye_gaze': '/api/v1/aria/api/eye-gaze/',
                        'slam_trajectory': '/api/v1/aria/api/slam-trajectory/'
                    },
                    'raw_apis': {
                        'raw_eye_gaze': '/api/v1/aria/raw/eye-gaze/',
                        'raw_slam_trajectory': '/api/v1/aria/raw/slam-trajectory/',
                        'raw_statistics': '/api/v1/aria/raw/statistics/'
                    }
                }
            })
            
        except Exception as e:
            logger.error(f"MPS ì§ì ‘ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
            return Response({
                'status': 'error',
                'message': f'MPS ì„í¬íŠ¸ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _import_eye_gaze_to_db(self, session):
        """Eye Gaze ë°ì´í„° ì§ì ‘ DB ì €ì¥"""
        try:
            count = 0
            
            # General Eye Gaze
            general_path = "/app/ARD/data/mps_samples/eye_gaze/general_eye_gaze.csv"
            general_gazes = mps.read_eyegaze(general_path)
            
            for gaze in general_gazes[::60]:  # 60ê°œë§ˆë‹¤ 1ê°œì”©
                EyeGazeData.objects.create(
                    session=session,
                    device_timestamp_ns=int(gaze.tracking_timestamp.total_seconds() * 1e9),
                    gaze_type='general',
                    yaw=float(gaze.yaw * 180 / 3.14159),
                    pitch=float(gaze.pitch * 180 / 3.14159),
                    depth_m=float(gaze.depth) if gaze.depth else 1.0,
                    confidence=0.95
                )
                count += 1
                if count >= 25:
                    break
            
            # Personalized Eye Gaze
            personalized_path = "/app/ARD/data/mps_samples/eye_gaze/personalized_eye_gaze.csv"
            personalized_gazes = mps.read_eyegaze(personalized_path)
            
            for gaze in personalized_gazes[::80]:  # 80ê°œë§ˆë‹¤ 1ê°œì”©
                EyeGazeData.objects.create(
                    session=session,
                    device_timestamp_ns=int(gaze.tracking_timestamp.total_seconds() * 1e9),
                    gaze_type='personalized',
                    yaw=float(gaze.yaw * 180 / 3.14159),
                    pitch=float(gaze.pitch * 180 / 3.14159),
                    depth_m=float(gaze.depth) if gaze.depth else 1.0,
                    confidence=0.98
                )
                count += 1
                if count >= 40:
                    break
            
            return count
            
        except Exception as e:
            logger.error(f"Eye Gaze ì§ì ‘ ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0
    
    def _import_slam_to_db(self, session):
        """SLAM ë°ì´í„° ì§ì ‘ DB ì €ì¥"""
        try:
            slam_path = "/app/ARD/data/mps_samples/slam/closed_loop_trajectory.csv"
            slam_poses = mps.read_closed_loop_trajectory(slam_path)
            
            count = 0
            for pose in slam_poses[::1200]:  # 1200ê°œë§ˆë‹¤ 1ê°œì”©
                try:
                    # SE3 ë³€í™˜ ì¶”ì¶œ
                    transform = pose.transform_world_device
                    translation = transform.translation()
                    
                    # ê°„ë‹¨í•œ ë³€í™˜ í–‰ë ¬ (íšŒì „ì€ ë‹¨ìœ„í–‰ë ¬ë¡œ ê·¼ì‚¬)
                    transform_matrix = [
                        [1.0, 0.0, 0.0, float(translation[0])],
                        [0.0, 1.0, 0.0, float(translation[1])],
                        [0.0, 0.0, 1.0, float(translation[2])],
                        [0.0, 0.0, 0.0, 1.0]
                    ]
                    
                    SLAMTrajectoryData.objects.create(
                        session=session,
                        device_timestamp_ns=int(pose.tracking_timestamp.total_seconds() * 1e9),
                        transform_matrix=transform_matrix,
                        position_x=float(translation[0]),
                        position_y=float(translation[1]),
                        position_z=float(translation[2])
                    )
                    count += 1
                    if count >= 40:
                        break
                        
                except Exception as e:
                    continue  # ê°œë³„ í•­ëª© ì‹¤íŒ¨ ì‹œ ìŠ¤í‚µ
            
            return count
            
        except Exception as e:
            logger.error(f"SLAM ì§ì ‘ ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0
    
    def _import_raw_eye_gaze_to_db(self, session):
        """Raw Eye Gaze ë°ì´í„° ì§ì ‘ DB ì €ì¥ (ì›ë³¸ CSV í•„ë“œ)"""
        try:
            # ê¸°ì¡´ Raw ë°ì´í„° ì‚­ì œ
            RawEyeGazeData.objects.filter(session__session_id__contains='mps').delete()
            
            count = 0
            
            # General Eye Gaze Raw ë°ì´í„°
            general_path = "/app/ARD/data/mps_samples/eye_gaze/general_eye_gaze.csv"
            import pandas as pd
            df = pd.read_csv(general_path)
            
            for idx, row in df.head(30).iterrows():  # 30ê°œë§Œ
                try:
                    RawEyeGazeData.objects.create(
                        session=session,
                        tracking_timestamp_us=int(row['tracking_timestamp_us']),
                        left_yaw_rads_cpf=float(row['left_yaw_rads_cpf']),
                        right_yaw_rads_cpf=float(row['right_yaw_rads_cpf']),
                        pitch_rads_cpf=float(row['pitch_rads_cpf']),
                        depth_m=float(row['depth_m']),
                        left_yaw_low_rads_cpf=float(row['left_yaw_low_rads_cpf']),
                        right_yaw_low_rads_cpf=float(row['right_yaw_low_rads_cpf']),
                        pitch_low_rads_cpf=float(row['pitch_low_rads_cpf']),
                        left_yaw_high_rads_cpf=float(row['left_yaw_high_rads_cpf']),
                        right_yaw_high_rads_cpf=float(row['right_yaw_high_rads_cpf']),
                        pitch_high_rads_cpf=float(row['pitch_high_rads_cpf']),
                        tx_left_eye_cpf=float(row['tx_left_eye_cpf']),
                        ty_left_eye_cpf=float(row['ty_left_eye_cpf']),
                        tz_left_eye_cpf=float(row['tz_left_eye_cpf']),
                        tx_right_eye_cpf=float(row['tx_right_eye_cpf']),
                        ty_right_eye_cpf=float(row['ty_right_eye_cpf']),
                        tz_right_eye_cpf=float(row['tz_right_eye_cpf']),
                        session_uid=row['session_uid'],
                        data_source='general_eye_gaze_csv'
                    )
                    count += 1
                except Exception as e:
                    continue  # ê°œë³„ í–‰ ì‹¤íŒ¨ ì‹œ ìŠ¤í‚µ
            
            return count
            
        except Exception as e:
            logger.error(f"Raw Eye Gaze ì§ì ‘ ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0
    
    def _import_raw_slam_to_db(self, session):
        """Raw SLAM ë°ì´í„° ì§ì ‘ DB ì €ì¥ (ì›ë³¸ CSV í•„ë“œ)"""
        try:
            # ê¸°ì¡´ Raw SLAM ë°ì´í„° ì‚­ì œ
            RawSlamTrajectoryData.objects.filter(session__session_id__contains='mps').delete()
            
            count = 0
            
            # SLAM Raw ë°ì´í„°
            slam_path = "/app/ARD/data/mps_samples/slam/closed_loop_trajectory.csv"
            import pandas as pd
            df = pd.read_csv(slam_path)
            
            for idx, row in df.head(25).iterrows():  # 25ê°œë§Œ
                try:
                    RawSlamTrajectoryData.objects.create(
                        session=session,
                        tracking_timestamp_ns=int(row['tracking_timestamp_ns']),
                        tx_world_device=float(row['tx_world_device']),
                        ty_world_device=float(row['ty_world_device']),
                        tz_world_device=float(row['tz_world_device']),
                        qx_world_device=float(row['qx_world_device']),
                        qy_world_device=float(row['qy_world_device']),
                        qz_world_device=float(row['qz_world_device']),
                        qw_world_device=float(row['qw_world_device']),
                        data_source='closed_loop_trajectory_csv'
                    )
                    count += 1
                except Exception as e:
                    continue  # ê°œë³„ í–‰ ì‹¤íŒ¨ ì‹œ ìŠ¤í‚µ
            
            return count
            
        except Exception as e:
            logger.error(f"Raw SLAM ì§ì ‘ ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0


class TestMessageView(APIView):
    """í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ View"""
    
    def post(self, request):
        serializer = TestMessageSerializer(data=request.data)
        if not serializer.is_valid():
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
        try:
            topic = serializer.validated_data['topic']
            message = serializer.validated_data['message']
            
            producer = AriaKafkaProducer()
            
            test_data = {
                'timestamp': datetime.utcnow().isoformat(),
                'message': message,
                'data_type': 'test_api',
                'source': 'django_class_based_view'
            }
            
            future = producer._get_producer().send(topic, value=test_data)
            result = future.get(timeout=10)
            producer.close()
            
            streaming_status['message_count'] += 1
            
            return Response({
                'status': 'success',
                'message': 'í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ê°€ ì„±ê³µì ìœ¼ë¡œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.',
                'topic': topic,
                'kafka_result': {
                    'topic': result.topic,
                    'partition': result.partition,
                    'offset': result.offset
                },
                'timestamp': datetime.utcnow().isoformat()
            })
            
        except Exception as e:
            return Response({
                'status': 'error',
                'message': f'ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class KafkaConsumerStatusViewSet(viewsets.ReadOnlyModelViewSet):
    """
    Kafka Consumer ìƒíƒœ ëª¨ë‹ˆí„°ë§ ViewSet
    """
    queryset = KafkaConsumerStatus.objects.all()
    serializer_class = KafkaConsumerStatusSerializer
    filter_backends = [DjangoFilterBackend, OrderingFilter]
    filterset_fields = ['consumer_group', 'topic', 'status']
    ordering_fields = ['last_processed_at', 'last_offset']
    ordering = ['-last_processed_at']
    
    @action(detail=False, methods=['get'])
    def health_check(self, request):
        """Consumer ê±´ê°• ìƒíƒœ ì²´í¬"""
        now = timezone.now()
        recent_threshold = now - timedelta(minutes=5)
        
        total_consumers = self.get_queryset().count()
        active_consumers = self.get_queryset().filter(status='ACTIVE').count()
        recent_active = self.get_queryset().filter(
            status='ACTIVE',
            last_processed_at__gte=recent_threshold
        ).count()
        
        health_status = 'healthy' if recent_active == active_consumers else 'warning'
        if active_consumers == 0:
            health_status = 'critical'
        
        return Response({
            'health_status': health_status,
            'total_consumers': total_consumers,
            'active_consumers': active_consumers,
            'recent_active_consumers': recent_active,
            'last_check': now.isoformat()
        })


def api_root_html(request):
    """
    HTML ë²„ì „ì˜ API Root í˜ì´ì§€
    """
    html = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>ARD (Aria Real-time Data) API v1</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 40px; }
            h1 { color: #333; }
            h2 { color: #666; margin-top: 30px; }
            .api-section { margin: 20px 0; }
            .api-link { display: block; padding: 8px 12px; margin: 4px 0; 
                       background: #f5f5f5; border-radius: 4px; text-decoration: none; 
                       color: #007cba; }
            .api-link:hover { background: #e8e8e8; }
            .description { color: #888; font-size: 14px; margin-bottom: 20px; }
        </style>
    </head>
    <body>
        <h1>ğŸ¯ ARD (Aria Real-time Data) API v1</h1>
        <p class="description">Meta Project Aria Real-time Data Processing System</p>
        
        <div class="api-section">
            <h2>ğŸ“Š Processed Data APIs (ì¼ë°˜ ì‚¬ìš©ììš©)</h2>
            <a href="/api/v1/aria/sessions/" class="api-link">Sessions (ì„¸ì…˜ ê´€ë¦¬)</a>
            <a href="/api/v1/aria/eye-gaze/" class="api-link">Eye Gaze (ì •ì œëœ ì‹œì„  ë°ì´í„°)</a>
            <a href="/api/v1/aria/hand-tracking/" class="api-link">Hand Tracking (ì •ì œëœ í•¸ë“œ íŠ¸ë˜í‚¹)</a>
            <a href="/api/v1/aria/slam-trajectory/" class="api-link">SLAM Trajectory (ì •ì œëœ SLAM ê¶¤ì )</a>
            <a href="/api/v1/aria/vrs-streams/" class="api-link">VRS Streams (ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼)</a>
            <a href="/api/v1/aria/imu-data/" class="api-link">IMU Data (ê´€ì„± ì„¼ì„œ)</a>
            <a href="/api/v1/aria/kafka-status/" class="api-link">Kafka Status (ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ)</a>
        </div>
        
        <div class="api-section">
            <h2>ğŸ”§ Raw Data APIs (MPS ì›ë³¸ ë°ì´í„°)</h2>
            <a href="/api/v1/aria/raw/statistics/" class="api-link">Raw Statistics (ì›ë³¸ ë°ì´í„° í†µê³„)</a>
            <a href="/api/v1/aria/raw/eye-gaze/" class="api-link">Raw Eye Gaze (MPS ì›ë³¸ ì‹œì„ )</a>
            <a href="/api/v1/aria/raw/hand-tracking/" class="api-link">Raw Hand Tracking (MPS ì›ë³¸ í•¸ë“œ)</a>
            <a href="/api/v1/aria/raw/slam-trajectory/" class="api-link">Raw SLAM Trajectory (MPS ì›ë³¸ SLAM)</a>
        </div>
        
        <div class="api-section">
            <h2>ğŸ“¦ Binary Data APIs (ê³ ì„±ëŠ¥ ìŠ¤íŠ¸ë¦¬ë°)</h2>
            <a href="/api/v1/aria/binary/registry/" class="api-link">Binary Registry (ë°”ì´ë„ˆë¦¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬)</a>
            <a href="/api/v1/aria/binary/metadata/" class="api-link">Binary Metadata (ë°”ì´ë„ˆë¦¬ ë©”íƒ€ë°ì´í„°)</a>
            <a href="/api/v1/aria/binary/streaming/" class="api-link">Binary Streaming (ìŠ¤íŠ¸ë¦¬ë° ì œì–´)</a>
            <a href="/api/v1/aria/binary/analytics/" class="api-link">Binary Analytics (ë°”ì´ë„ˆë¦¬ ë¶„ì„)</a>
        </div>
        
        <div class="api-section">
            <h2>ğŸ® Control APIs (ì‹œìŠ¤í…œ ì œì–´)</h2>
            <a href="/api/v1/aria/streaming/" class="api-link">Streaming Control (ìŠ¤íŠ¸ë¦¬ë° ì œì–´)</a>
            <a href="/api/v1/aria/test-message/" class="api-link">Test Message (í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€)</a>
            <a href="/api/v1/aria/binary/test-message/" class="api-link">Binary Test (ë°”ì´ë„ˆë¦¬ í…ŒìŠ¤íŠ¸)</a>
        </div>
        
        <div class="api-section">
            <h2>ğŸ’¡ Quick Examples</h2>
            <a href="/api/v1/aria/eye-gaze/" class="api-link">Processed Eye Gaze (ì •ì œëœ ì‹œì„  ë°ì´í„°)</a>
            <a href="/api/v1/aria/raw/eye-gaze/" class="api-link">Raw Eye Gaze with All Fields (ëª¨ë“  ì›ë³¸ í•„ë“œ)</a>
            <a href="/api/v1/aria/raw/statistics/" class="api-link">Raw Data Statistics (ì›ë³¸ ë°ì´í„° í†µê³„)</a>
        </div>
    </body>
    </html>
    """
    return HttpResponse(html)

@api_view(['GET'])
def api_root(request, format=None):
    """
    ARD (Aria Real-time Data) API Root
    - Processed Data APIs: ì¼ë°˜ ì‚¬ìš©ììš© ì •ì œëœ ë°ì´í„°
    - Raw Data APIs: ê³ ê¸‰ ì‚¬ìš©ììš© MPS ì›ë³¸ ë°ì´í„°  
    - Binary Data APIs: ê³ ì„±ëŠ¥ ë°”ì´ë„ˆë¦¬ ìŠ¤íŠ¸ë¦¬ë°
    """
    return Response({
        'ğŸ¯ ARD Aria Streams API v1': {
            'description': 'Meta Project Aria Real-time Data Processing System',
            'version': '1.0',
            'documentation': request.build_absolute_uri('/api/v1/aria/'),
        },
        
        'ğŸ“Š Processed Data APIs (ì¼ë°˜ ì‚¬ìš©ììš©)': {
            'sessions': request.build_absolute_uri('/api/v1/aria/api/sessions/'),
            'eye-gaze': request.build_absolute_uri('/api/v1/aria/api/eye-gaze/'),
            'hand-tracking': request.build_absolute_uri('/api/v1/aria/api/hand-tracking/'),
            'slam-trajectory': request.build_absolute_uri('/api/v1/aria/api/slam-trajectory/'),
            'vrs-streams': request.build_absolute_uri('/api/v1/aria/api/vrs-streams/'),
            'imu-data': request.build_absolute_uri('/api/v1/aria/api/imu-data/'),
            'kafka-status': request.build_absolute_uri('/api/v1/aria/api/kafka-status/'),
        },
        
        'ğŸ”§ Raw Data APIs (MPS ì›ë³¸ ë°ì´í„°)': {
            'raw-statistics': request.build_absolute_uri('/api/v1/aria/raw/statistics/'),
            'raw-eye-gaze': request.build_absolute_uri('/api/v1/aria/raw/eye-gaze/'),
            'raw-hand-tracking': request.build_absolute_uri('/api/v1/aria/raw/hand-tracking/'),
            'raw-slam-trajectory': request.build_absolute_uri('/api/v1/aria/raw/slam-trajectory/'),
        },
        
        'ğŸ“¦ Binary Data APIs (ê³ ì„±ëŠ¥ ìŠ¤íŠ¸ë¦¬ë°)': {
            'binary-registry': request.build_absolute_uri('/api/v1/aria/binary/api/registry/'),
            'binary-metadata': request.build_absolute_uri('/api/v1/aria/binary/api/metadata/'),
            'binary-streaming': request.build_absolute_uri('/api/v1/aria/binary/streaming/'),
            'binary-analytics': request.build_absolute_uri('/api/v1/aria/binary/analytics/'),
        },
        
        'ğŸ® Control APIs (ì‹œìŠ¤í…œ ì œì–´)': {
            'streaming-control': request.build_absolute_uri('/api/v1/aria/streaming/'),
            'test-message': request.build_absolute_uri('/api/v1/aria/test-message/'),
            'binary-test': request.build_absolute_uri('/api/v1/aria/binary/test-message/'),
        },
        
        'ğŸ’¡ Quick Examples': {
            'processed_eye_gaze': request.build_absolute_uri('/api/v1/aria/eye-gaze/'),
            'raw_eye_gaze_with_all_fields': request.build_absolute_uri('/api/v1/aria/raw/eye-gaze/'),
            'binary_frame_access': request.build_absolute_uri('/api/v1/aria/binary/data/{frame_id}/'),
            'raw_statistics': request.build_absolute_uri('/api/v1/aria/raw/statistics/'),
            'vrs_image_view': request.build_absolute_uri('/api/v1/aria/simple-image/'),
        }
    })


class SimpleImageView(APIView):
    """ê°„ë‹¨í•œ VRS ì´ë¯¸ì§€ ë·° - Kafkaì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°"""
    permission_classes = [permissions.AllowAny]
    
    def get(self, request):
        """ìµœê·¼ VRS ì´ë¯¸ì§€ë¥¼ Kafkaì—ì„œ ê°€ì ¸ì™€ì„œ í‘œì‹œ"""
        try:
            import os
            import json
            
            bootstrap_servers = os.getenv('KAFKA_BOOTSTRAP_SERVERS', 'ARD_KAFKA:9092')
            
            # ë©”íƒ€ë°ì´í„° í† í”½ì—ì„œ ìµœê·¼ ì´ë¯¸ì§€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            metadata_consumer = KafkaConsumer(
                'vrs-metadata-stream',
                bootstrap_servers=bootstrap_servers,
                value_deserializer=lambda m: json.loads(m.decode('utf-8')),
                consumer_timeout_ms=3000,
                auto_offset_reset='earliest'
            )
            
            # ë°”ì´ë„ˆë¦¬ í† í”½ì—ì„œ ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°  
            binary_consumer = KafkaConsumer(
                'vrs-binary-stream',
                bootstrap_servers=bootstrap_servers,
                consumer_timeout_ms=3000,
                auto_offset_reset='earliest'
            )
            
            # ìµœê·¼ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            latest_metadata = None
            for message in metadata_consumer:
                latest_metadata = message.value
            
            if not latest_metadata:
                return Response({
                    'error': 'No VRS image found in Kafka',
                    'suggestion': 'Generate VRS image: POST /api/v1/aria/binary/test-message/'
                })
            
            # í•´ë‹¹í•˜ëŠ” ë°”ì´ë„ˆë¦¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            frame_id = latest_metadata['frame_id']
            binary_data = None
            
            for message in binary_consumer:
                if message.key and message.key.decode('utf-8') == frame_id:
                    binary_data = message.value
                    break
            
            metadata_consumer.close()
            binary_consumer.close()
            
            if not binary_data:
                return Response({
                    'error': 'VRS binary data not found',
                    'frame_id': frame_id,
                    'metadata': latest_metadata
                })
            
            # ì´ë¯¸ì§€ ë°ì´í„° ë°˜í™˜
            format_type = request.GET.get('format', 'raw')
            
            if format_type == 'base64':
                return Response({
                    'frame_id': frame_id,
                    'image_data': base64.b64encode(binary_data).decode('utf-8'),
                    'metadata': latest_metadata,
                    'size_bytes': len(binary_data),
                    'source': 'VRS sample.vrs file'
                })
            elif format_type == 'info':
                return Response({
                    'frame_id': frame_id,
                    'metadata': latest_metadata,
                    'size_bytes': len(binary_data),
                    'source': 'VRS sample.vrs RGB camera stream (214-1)',
                    'image_url': f'/api/v1/aria/simple-image/?format=raw',
                    'base64_url': f'/api/v1/aria/simple-image/?format=base64'
                })
            else:  # raw format - ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼
                response = HttpResponse(binary_data, content_type='image/jpeg')
                response['Content-Length'] = len(binary_data)
                response['X-Frame-ID'] = frame_id
                response['X-VRS-Source'] = 'sample.vrs RGB stream'
                response['Content-Disposition'] = f'inline; filename="{frame_id}.jpg"'
                return response
                
        except Exception as e:
            return Response({
                'error': f'Failed to get VRS image: {str(e)}',
                'suggestion': 'Make sure Kafka is running and has VRS image data'
            }, status=500)


class QuickImageGenerator(APIView):
    """ë¹ ë¥¸ VRS ì´ë¯¸ì§€ ìƒì„±ê¸°"""
    permission_classes = [permissions.AllowAny]
    
    def post(self, request):
        """VRSì—ì„œ ìƒˆ ì´ë¯¸ì§€ë¥¼ ë¹ ë¥´ê²Œ ìƒì„±"""
        try:
            from common.kafka.binary_producer import BinaryKafkaProducer
            
            producer = BinaryKafkaProducer()
            result = producer.send_test_binary_frame('vrs-quick-image')
            producer.close()
            
            if result['success']:
                return Response({
                    'success': True,
                    'message': 'VRS ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!',
                    'frame_id': result['frame_id'],
                    'source': 'VRS sample.vrs RGB camera',
                    'view_urls': {
                        'image': '/api/v1/aria/simple-image/?format=raw',
                        'base64': '/api/v1/aria/simple-image/?format=base64', 
                        'info': '/api/v1/aria/simple-image/?format=info'
                    },
                    'metadata': result['metadata']
                })
            else:
                return Response({
                    'success': False,
                    'error': result.get('error', 'Unknown error')
                }, status=500)
                
        except Exception as e:
            return Response({
                'success': False,
                'error': str(e)
            }, status=500)


class DirectImageView(APIView):
    """ì§ì ‘ ì´ë¯¸ì§€ ë³´ê¸° - ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•"""
    permission_classes = [permissions.AllowAny]
    
    def get(self, request):
        """Kafkaì—ì„œ ìµœì‹  ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì™€ì„œ ë°”ë¡œ í‘œì‹œ"""
        try:
            import os
            from kafka import KafkaConsumer
            import json
            
            # Kafka ì„¤ì •
            bootstrap_servers = os.getenv('KAFKA_BOOTSTRAP_SERVERS', 'ARD_KAFKA:9092')
            
            # ë°”ì´ë„ˆë¦¬ í† í”½ì—ì„œ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ì½ì–´ì„œ ê°€ì¥ ìµœì‹  ê²ƒ ì„ íƒ  
            consumer = KafkaConsumer(
                'vrs-binary-stream',
                bootstrap_servers=bootstrap_servers,
                consumer_timeout_ms=3000,  # 3ì´ˆ ê¸°ë‹¤ë¦¼
                auto_offset_reset='earliest',  # ì²˜ìŒë¶€í„° ì½ê¸°
                enable_auto_commit=False,
                max_poll_records=50  # ìµœëŒ€ 50ê°œ í™•ì¸
            )
            
            # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§‘í•´ì„œ ê°€ì¥ ìµœì‹  ê²ƒ ì„ íƒ
            all_images = []
            
            logger.info(f"Collecting all images from Kafka...")
            
            for message in consumer:
                if message.value and len(message.value) > 1000:  # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
                    key = message.key.decode('utf-8') if message.key else 'unknown'
                    all_images.append({
                        'key': key,
                        'data': message.value,
                        'timestamp': message.timestamp,
                        'offset': message.offset
                    })
                    logger.info(f"Found image: {key}, size: {len(message.value)} bytes, offset: {message.offset}")
            
            # ê°€ì¥ ìµœì‹  ì´ë¯¸ì§€ ì„ íƒ (ê°€ì¥ ë†’ì€ offset)
            latest_image = None
            latest_key = None
            
            if all_images:
                # offsetì´ ê°€ì¥ ë†’ì€ ê²ƒì´ ê°€ì¥ ìµœì‹ 
                latest_msg = max(all_images, key=lambda x: x['offset'])
                latest_image = latest_msg['data']
                latest_key = latest_msg['key']
                logger.info(f"Selected latest image: {latest_key}, size: {len(latest_image)} bytes")
            
            consumer.close()
            
            if latest_image:
                # ì´ë¯¸ì§€ ë°˜í™˜
                response = HttpResponse(latest_image, content_type='image/jpeg')
                response['Content-Length'] = len(latest_image)
                response['X-Frame-ID'] = latest_key
                response['Content-Disposition'] = f'inline; filename="{latest_key}.jpg"'
                response['Cache-Control'] = 'no-cache'
                logger.info(f"Serving image: {latest_key}, {len(latest_image)} bytes")
                return response
            else:
                # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±í•˜ê³  ë°˜í™˜
                logger.warning("No image found in Kafka, generating test image...")
                return self._generate_and_serve_test_image()
                
        except Exception as e:
            logger.error(f"Direct image view failed: {e}")
            return Response({
                'error': f'Failed to get image: {str(e)}',
                'suggestion': 'Make sure Kafka is running with binary data'
            }, status=500)
    
    def _generate_and_serve_test_image(self):
        """í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± í›„ ë°”ë¡œ ë°˜í™˜"""
        try:
            from common.kafka.binary_producer import BinaryKafkaProducer
            
            # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
            producer = BinaryKafkaProducer()
            result = producer.send_test_binary_frame('direct-test-session')
            producer.close()
            
            if result['success'] and 'binary_data' in result:
                binary_data = result['binary_data']
                frame_id = result['frame_id']
                
                response = HttpResponse(binary_data, content_type='image/jpeg')
                response['Content-Length'] = len(binary_data)
                response['X-Frame-ID'] = frame_id
                response['Content-Disposition'] = f'inline; filename="{frame_id}.jpg"'
                response['X-Generated'] = 'true'
                
                logger.info(f"Generated and serving test image: {frame_id}, {len(binary_data)} bytes")
                return response
            else:
                return Response({
                    'error': 'Failed to generate test image',
                    'details': result
                }, status=500)
                
        except Exception as e:
            logger.error(f"Test image generation failed: {e}")
            return Response({
                'error': f'Test image generation failed: {str(e)}'
            }, status=500)


class ImageMetadataListView(APIView):
    """ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ëª©ë¡ - í´ë¦­í•˜ë©´ ì´ë¯¸ì§€ ë³´ê¸°"""
    permission_classes = [permissions.AllowAny]
    
    def get(self, request):
        """Kafkaì—ì„œ ëª¨ë“  ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        try:
            import os
            from kafka import KafkaConsumer
            import json
            from datetime import datetime
            
            # Kafka ì„¤ì •
            bootstrap_servers = os.getenv('KAFKA_BOOTSTRAP_SERVERS', 'ARD_KAFKA:9092')
            
            # ë©”íƒ€ë°ì´í„° í† í”½ì—ì„œ ëª¨ë“  ì´ë¯¸ì§€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            consumer = KafkaConsumer(
                'vrs-metadata-stream',
                bootstrap_servers=bootstrap_servers,
                consumer_timeout_ms=3000,
                auto_offset_reset='earliest',
                value_deserializer=lambda m: json.loads(m.decode('utf-8'))
            )
            
            metadata_list = []
            
            for message in consumer:
                metadata = message.value
                if metadata.get('data_type') == 'vrs_frame_binary':
                    # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì½ê¸° ì‰½ê²Œ ë³€í™˜
                    try:
                        timestamp_iso = metadata.get('timestamp', '')
                        if timestamp_iso:
                            dt = datetime.fromisoformat(timestamp_iso.replace('Z', '+00:00'))
                            readable_time = dt.strftime('%Y-%m-%d %H:%M:%S')
                        else:
                            readable_time = 'Unknown'
                    except:
                        readable_time = 'Invalid'
                    
                    metadata_item = {
                        'frame_id': metadata.get('frame_id'),
                        'session_id': metadata.get('session_id'),
                        'stream_id': metadata.get('stream_id'),
                        'frame_index': metadata.get('frame_index'),
                        'image_size': f"{metadata.get('image_width', 0)}x{metadata.get('image_height', 0)}",
                        'timestamp': readable_time,
                        'compressed_size': metadata.get('compression', {}).get('compressed_size', 0),
                        'compression_ratio': round(metadata.get('compression', {}).get('compression_ratio', 0), 3),
                        'image_url': f'/api/v1/aria/image-by-id/{metadata.get("frame_id")}/',
                        'is_real_vrs': 'real-vrs-session' in metadata.get('session_id', ''),
                        'capture_timestamp_ns': metadata.get('capture_timestamp_ns')
                    }
                    metadata_list.append(metadata_item)
            
            consumer.close()
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ìˆœìœ¼ë¡œ ì •ë ¬ (ìµœì‹  ë¨¼ì €)
            metadata_list.sort(key=lambda x: x.get('capture_timestamp_ns', 0), reverse=True)
            
            return Response({
                'success': True,
                'total_images': len(metadata_list),
                'images': metadata_list,
                'instructions': {
                    'how_to_view': 'Click on image_url to view the actual image',
                    'real_vrs_data': 'Items with is_real_vrs=true are from actual VRS sample.vrs file',
                    'test_data': 'Items with is_real_vrs=false are generated test images'
                }
            })
            
        except Exception as e:
            return Response({
                'error': f'Failed to get metadata: {str(e)}',
                'suggestion': 'Make sure Kafka is running with metadata'
            }, status=500)


class ImageByIdView(APIView):
    """íŠ¹ì • Frame IDë¡œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°"""
    permission_classes = [permissions.AllowAny]
    
    def get(self, request, frame_id):
        """Frame IDë¡œ íŠ¹ì • ì´ë¯¸ì§€ ë°˜í™˜"""
        try:
            import os
            from kafka import KafkaConsumer
            
            # Kafka ì„¤ì •
            bootstrap_servers = os.getenv('KAFKA_BOOTSTRAP_SERVERS', 'ARD_KAFKA:9092')
            
            # ë°”ì´ë„ˆë¦¬ í† í”½ì—ì„œ í•´ë‹¹ Frame ID ì°¾ê¸°
            consumer = KafkaConsumer(
                'vrs-binary-stream',
                bootstrap_servers=bootstrap_servers,
                consumer_timeout_ms=5000,
                auto_offset_reset='earliest',
                enable_auto_commit=False
            )
            
            target_image = None
            
            logger.info(f"Looking for image with frame_id: {frame_id}")
            
            for message in consumer:
                if message.key and message.key.decode('utf-8') == frame_id:
                    if message.value and len(message.value) > 1000:
                        target_image = message.value
                        logger.info(f"Found target image: {frame_id}, size: {len(target_image)} bytes")
                        break
            
            consumer.close()
            
            if target_image:
                response = HttpResponse(target_image, content_type='image/jpeg')
                response['Content-Length'] = len(target_image)
                response['X-Frame-ID'] = frame_id
                response['Content-Disposition'] = f'inline; filename="{frame_id}.jpg"'
                response['Cache-Control'] = 'no-cache'
                return response
            else:
                return Response({
                    'error': f'Image not found for frame_id: {frame_id}',
                    'suggestion': 'Check if the frame_id exists in the image list'
                }, status=404)
                
        except Exception as e:
            logger.error(f"Image by ID view failed: {e}")
            return Response({
                'error': f'Failed to get image: {str(e)}'
            }, status=500)