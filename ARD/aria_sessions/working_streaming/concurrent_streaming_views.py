"""
ë™ì‹œ 4ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¬ë° - Project Aria ê³µì‹ Observer íŒ¨í„´ êµ¬í˜„
Facebook Research ê³µì‹ ë¬¸ì„œ ê¸°ë°˜: deliver_queued_sensor_data + Kafka
"""

from django.http import JsonResponse, HttpResponse
from django.views import View
from django.views.decorators.csrf import csrf_exempt
from django.utils.decorators import method_decorator
import json
import time
import logging
import threading
import asyncio
from queue import Queue, Empty
from typing import Dict, Optional
import numpy as np

# Project Aria ê³µì‹ SDK
try:
    from projectaria_tools.core import data_provider
    from projectaria_tools.core.sensor_data import TimeDomain, TimeQueryOptions
    from projectaria_tools.core.stream_id import RecordableTypeId, StreamId
    ARIA_SDK_AVAILABLE = True
except ImportError:
    ARIA_SDK_AVAILABLE = False

from aria_sessions.models import AriaStreamingSession

logger = logging.getLogger(__name__)

class ConcurrentAriaObserver:
    """
    Project Aria ê³µì‹ Observer íŒ¨í„´ êµ¬í˜„ - 4ì¹´ë©”ë¼ ë™ì‹œ ì§€ì›
    """
    def __init__(self):
        # 4ê°œ ì¹´ë©”ë¼ë³„ ì´ë¯¸ì§€ ì €ì¥ (ê³µì‹ íŒ¨í„´)
        self.images = {}  # camera_id -> latest_image
        self.frame_counts = {}  # camera_id -> count
        self.image_queues = {}  # camera_id -> Queue
        
        # ì¹´ë©”ë¼ ID ë§¤í•‘ (ê³µì‹ ìŠ¤íŠ¸ë¦¼ ID)
        self.camera_mappings = {
            'rgb': {'stream_id': StreamId("214-1"), 'name': 'camera-rgb'},
            'slam-left': {'stream_id': StreamId("1201-1"), 'name': 'camera-slam-left'}, 
            'slam-right': {'stream_id': StreamId("1201-2"), 'name': 'camera-slam-right'},
            'eye-tracking': {'stream_id': StreamId("211-1"), 'name': 'camera-et'}
        }
        
        # ê° ì¹´ë©”ë¼ë³„ Queue ì´ˆê¸°í™”
        for camera_type in self.camera_mappings.keys():
            self.image_queues[camera_type] = Queue(maxsize=2)
            self.frame_counts[camera_type] = 0
        
        print("âœ… ConcurrentAriaObserver ì´ˆê¸°í™” - 4ì¹´ë©”ë¼ ë™ì‹œ ì§€ì›")
    
    def on_image_received(self, image: np.array, record, camera_type: str):
        """
        ê³µì‹ Observer íŒ¨í„´ ì½œë°± - on_image_received(image, record)
        """
        try:
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ
            timestamp_ns = record.capture_timestamp_ns if hasattr(record, 'capture_timestamp_ns') else int(time.time() * 1e9)
            
            # í”„ë ˆì„ ì¹´ìš´íŠ¸ ì¦ê°€
            self.frame_counts[camera_type] = self.frame_counts[camera_type] + 1
            
            # JPEG ì••ì¶•
            import cv2
            _, buffer = cv2.imencode('.jpg', image, [cv2.IMWRITE_JPEG_QUALITY, 75])  # ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ í’ˆì§ˆ 75ë¡œ ì„¤ì •
            image_bytes = buffer.tobytes()
            
            # Queueì— ìµœì‹  ì´ë¯¸ì§€ ì €ì¥
            if self.image_queues[camera_type].full():
                try:
                    self.image_queues[camera_type].get_nowait()
                except Empty:
                    pass
            
            image_data = {
                'image_data': image_bytes,
                'timestamp_ns': timestamp_ns,
                'frame_number': self.frame_counts[camera_type],
                'camera_type': camera_type,
                'content_type': 'image/jpeg'
            }
            
            self.image_queues[camera_type].put(image_data)
            self.images[camera_type] = image_data
            
            print(f"ğŸ”¥ [{camera_type}] Frame {self.frame_counts[camera_type]}, {len(image_bytes)} bytes")
            
        except Exception as e:
            logger.error(f"Observer ì½œë°± ì˜¤ë¥˜ [{camera_type}]: {e}")
    
    def get_latest_image(self, camera_type: str) -> Optional[dict]:
        """íŠ¹ì • ì¹´ë©”ë¼ì˜ ìµœì‹  ì´ë¯¸ì§€ ë°˜í™˜"""
        try:
            return self.image_queues[camera_type].get_nowait()
        except Empty:
            return None
    
    def get_all_latest_images(self) -> Dict[str, dict]:
        """ëª¨ë“  ì¹´ë©”ë¼ì˜ ìµœì‹  ì´ë¯¸ì§€ ë°˜í™˜"""
        result = {}
        for camera_type in self.camera_mappings.keys():
            latest = self.get_latest_image(camera_type)
            if latest:
                result[camera_type] = latest
        return result


class ConcurrentAriaStreaming:
    """
    Project Aria ê³µì‹ deliver_queued_sensor_data ê¸°ë°˜ ë™ì‹œ ìŠ¤íŠ¸ë¦¬ë°
    """
    def __init__(self, vrs_file_path: str):
        self.vrs_file_path = vrs_file_path
        self.provider = None
        self.observer = ConcurrentAriaObserver()
        self.is_streaming = False
        self.streaming_thread = None
        
        # VRS í”„ë¡œë°”ì´ë” ì´ˆê¸°í™”
        try:
            self.provider = data_provider.create_vrs_data_provider(vrs_file_path)
            if not self.provider:
                raise Exception("Invalid VRS data provider")
            print(f"âœ… VRS í”„ë¡œë°”ì´ë” ìƒì„±: {vrs_file_path}")
        except Exception as e:
            logger.error(f"VRS ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def setup_concurrent_streaming_options(self):
        """
        ê³µì‹ deliver_queued_sensor_data ì˜µì…˜ ì„¤ì • - 4ì¹´ë©”ë¼ ë™ì‹œ
        """
        # Step 1: ê³µì‹ íŒ¨í„´ - ê¸°ë³¸ ì˜µì…˜ íšë“
        options = self.provider.get_default_deliver_queued_options()
        
        # Step 2: ì‹œê°„ ë²”ìœ„ ì„¤ì • (ì„±ëŠ¥ì„ ìœ„í•´ ì§§ê²Œ)
        options.set_truncate_first_device_time_ns(int(1e8))  # 0.1ì´ˆ í›„
        options.set_truncate_last_device_time_ns(int(2e9))   # 2ì´ˆ ì „ (ë” ì§§ê²Œ)
        
        # Step 3: ëª¨ë“  ì„¼ì„œ ë¹„í™œì„±í™” í›„ ì¹´ë©”ë¼ë§Œ í™œì„±í™”
        options.deactivate_stream_all()
        
        # Step 4: 4ê°œ ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ í™œì„±í™”
        for camera_type, config in self.observer.camera_mappings.items():
            try:
                stream_id = config['stream_id']
                options.activate_stream(stream_id)
                options.set_subsample_rate(stream_id, 3)  # ì„±ëŠ¥ í–¥ìƒ: 3í”„ë ˆì„ë§ˆë‹¤ 1ê°œì”©
                print(f"âœ… {camera_type} ({stream_id}) í™œì„±í™”")
            except Exception as e:
                print(f"âŒ {camera_type} í™œì„±í™” ì‹¤íŒ¨: {e}")
        
        return options
    
    def start_concurrent_streaming(self):
        """ë™ì‹œ 4ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘"""
        if self.is_streaming:
            return "ì´ë¯¸ ìŠ¤íŠ¸ë¦¬ë° ì¤‘"
        
        self.is_streaming = True
        self.streaming_thread = threading.Thread(target=self._concurrent_streaming_loop)
        self.streaming_thread.daemon = True
        self.streaming_thread.start()
        
        print("ğŸš€ ë™ì‹œ 4ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘")
        return "ë™ì‹œ 4ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ë¨"
    
    def stop_streaming(self):
        """ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€"""
        self.is_streaming = False
        if self.streaming_thread:
            self.streaming_thread.join(timeout=5.0)
        print("â¹ï¸ ë™ì‹œ 4ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€")
        return "ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€ë¨"
    
    def _concurrent_streaming_loop(self):
        """
        ê³µì‹ deliver_queued_sensor_data ì´í„°ë ˆì´í„° ê¸°ë°˜ ë™ì‹œ ìŠ¤íŠ¸ë¦¬ë° ë£¨í”„ + ìˆœí™˜ ì¬ìƒ
        """
        replay_count = 0
        
        while self.is_streaming:
            try:
                replay_count += 1
                print(f"ğŸ”„ ìŠ¤íŠ¸ë¦¬ë° ìˆœí™˜ ì¬ìƒ ì‹œì‘ - {replay_count}íšŒì°¨")
                
                # ê³µì‹ ì˜µì…˜ ì„¤ì •
                options = self.setup_concurrent_streaming_options()
                
                # ê³µì‹ ì´í„°ë ˆì´í„° ìƒì„±
                iterator = self.provider.deliver_queued_sensor_data(options)
                
                print(f"ğŸ”¥ ê³µì‹ deliver_queued_sensor_data ì´í„°ë ˆì´í„° ì‹œì‘ ({replay_count}íšŒì°¨)")
                
                # ìŠ¤íŠ¸ë¦¼ ID -> camera_type ë§¤í•‘ ìƒì„±
                stream_to_camera = {}
                for camera_type, config in self.observer.camera_mappings.items():
                    stream_to_camera[str(config['stream_id'])] = camera_type
                
                frame_count_in_cycle = 0
                
                for sensor_data in iterator:
                    if not self.is_streaming:
                        break
                    
                    # ì„¼ì„œ ë°ì´í„° ì •ë³´ ì¶”ì¶œ
                    stream_id = str(sensor_data.stream_id())
                    sensor_type = sensor_data.sensor_data_type()
                    
                    # ì´ë¯¸ì§€ ë°ì´í„°ë§Œ ì²˜ë¦¬
                    if str(sensor_type) == 'SensorDataType.IMAGE':
                        camera_type = stream_to_camera.get(stream_id)
                        if camera_type:
                            try:
                                # ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ
                                image_data, record = sensor_data.image_data_and_record()
                                image_array = image_data.to_numpy_array()
                                
                                # Observer ì½œë°± í˜¸ì¶œ (ê³µì‹ íŒ¨í„´)
                                self.observer.on_image_received(image_array, record, camera_type)
                                frame_count_in_cycle += 1
                                
                            except Exception as e:
                                logger.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜ [{camera_type}]: {e}")
                
                print(f"âœ… {replay_count}íšŒì°¨ ìˆœí™˜ ì™„ë£Œ (ì´ {frame_count_in_cycle} í”„ë ˆì„)")
                
                # ìŠ¤íŠ¸ë¦¬ë°ì´ ê³„ì† í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ë‹¤ì‹œ ì‹œì‘
                if self.is_streaming:
                    print("ğŸ”„ VRS ë°ì´í„° ë - ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì¬ìƒ")
                    time.sleep(0.1)  # ì§§ì€ ëŒ€ê¸° í›„ ì¬ì‹œì‘
                    
            except Exception as e:
                logger.error(f"ë™ì‹œ ìŠ¤íŠ¸ë¦¬ë° ë£¨í”„ ì˜¤ë¥˜ ({replay_count}íšŒì°¨): {e}")
                print(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜ ({replay_count}íšŒì°¨): {e}")
                
                # ì˜¤ë¥˜ ë°œìƒì‹œ ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
                if self.is_streaming:
                    print("â³ 3ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(3)
        
        print(f"â¹ï¸ ë™ì‹œ ìŠ¤íŠ¸ë¦¬ë° ë£¨í”„ ì¢…ë£Œ (ì´ {replay_count}íšŒì°¨ ì¬ìƒ)")


# ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤
concurrent_streaming = None

def get_concurrent_streaming():
    """ê¸€ë¡œë²Œ ë™ì‹œ ìŠ¤íŠ¸ë¦¬ë° ì¸ìŠ¤í„´ìŠ¤ íšë“"""
    global concurrent_streaming
    
    if concurrent_streaming is None:
        # ì²« ë²ˆì§¸ available ì„¸ì…˜ ì‚¬ìš©
        session = AriaStreamingSession.objects.filter(status='READY').first()
        if not session:
            raise Exception("No available streaming session")
        
        concurrent_streaming = ConcurrentAriaStreaming(session.vrs_file_path)
    
    return concurrent_streaming


@method_decorator(csrf_exempt, name='dispatch')
class ConcurrentStreamingControlView(View):
    """ë™ì‹œ 4ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¬ë° ì œì–´ API"""
    
    def post(self, request, action):
        """ìŠ¤íŠ¸ë¦¬ë° ì œì–´"""
        try:
            streaming = get_concurrent_streaming()
            
            if action == 'start':
                result = streaming.start_concurrent_streaming()
                return JsonResponse({
                    'status': 'success',
                    'message': result,
                    'method': 'ê³µì‹ deliver_queued_sensor_data + Observer',
                    'cameras': list(streaming.observer.camera_mappings.keys()),
                    'streaming': streaming.is_streaming
                })
                
            elif action == 'stop':
                result = streaming.stop_streaming()
                return JsonResponse({
                    'status': 'success',
                    'message': result,
                    'streaming': streaming.is_streaming
                })
                
            else:
                return JsonResponse({
                    'status': 'error',
                    'message': 'Invalid action'
                }, status=400)
                
        except Exception as e:
            return JsonResponse({
                'status': 'error',
                'message': str(e)
            }, status=500)


class ConcurrentLatestFrameView(View):
    """ë™ì‹œ 4ì¹´ë©”ë¼ ìµœì‹  í”„ë ˆì„ API"""
    
    def get(self, request):
        """íŠ¹ì • ì¹´ë©”ë¼ì˜ ìµœì‹  í”„ë ˆì„ ë°˜í™˜"""
        try:
            streaming = get_concurrent_streaming()
            camera_type = request.GET.get('camera', 'rgb')
            
            if camera_type not in streaming.observer.camera_mappings:
                return HttpResponse(f"Invalid camera type: {camera_type}", status=400)
            
            latest_image = streaming.observer.get_latest_image(camera_type)
            
            if latest_image is None:
                return HttpResponse(
                    status=204,  # No Content
                    headers={'Cache-Control': 'no-cache'}
                )
            
            response = HttpResponse(
                latest_image['image_data'],
                content_type=latest_image['content_type']
            )
            response['Cache-Control'] = 'no-cache'
            response['X-Frame-Number'] = str(latest_image['frame_number'])
            response['X-Timestamp-NS'] = str(latest_image['timestamp_ns'])
            response['X-Camera-Type'] = latest_image['camera_type']
            response['X-Source'] = 'concurrent-observer'
            
            return response
            
        except Exception as e:
            logger.error(f"ìµœì‹  í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return HttpResponse(f"Frame error: {str(e)}", status=500)


class ConcurrentMultiFrameView(View):
    """ë™ì‹œ 4ì¹´ë©”ë¼ ë‹¤ì¤‘ í”„ë ˆì„ API"""
    
    def get(self, request):
        """ëª¨ë“  ì¹´ë©”ë¼ì˜ ìµœì‹  í”„ë ˆì„ì„ JSONìœ¼ë¡œ ë°˜í™˜"""
        try:
            streaming = get_concurrent_streaming()
            all_images = streaming.observer.get_all_latest_images()
            
            result = {}
            for camera_type, image_data in all_images.items():
                # Base64 ì¸ì½”ë”©
                import base64
                image_base64 = base64.b64encode(image_data['image_data']).decode('utf-8')
                
                result[camera_type] = {
                    'frame_number': image_data['frame_number'],
                    'timestamp_ns': image_data['timestamp_ns'],
                    'camera_type': image_data['camera_type'],
                    'image_base64': image_base64
                }
            
            return JsonResponse({
                'status': 'success',
                'method': 'ê³µì‹ Observer íŒ¨í„´',
                'cameras': result,
                'camera_count': len(result),
                'total_frames': sum(streaming.observer.frame_counts.values())
            })
            
        except Exception as e:
            logger.error(f"ë‹¤ì¤‘ í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return JsonResponse({
                'status': 'error',
                'message': str(e)
            }, status=500)


class ConcurrentStreamingPageView(View):
    """ë™ì‹œ 4ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¬ë° í˜ì´ì§€"""
    
    def get(self, request):
        """ë™ì‹œ 4ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¬ë° HTML í˜ì´ì§€"""
        
        html_template = '''
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ğŸ”¥ ë™ì‹œ 4ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¬ë°</title>
    <style>
        body {
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            color: white;
        }
        
        .container {
            max-width: 1600px;
            margin: 0 auto;
        }
        
        .header {
            text-align: center;
            margin-bottom: 30px;
        }
        
        .title {
            font-size: 2.5rem;
            margin: 0;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        
        .cameras-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-bottom: 30px;
        }
        
        .camera-box {
            background: rgba(255,255,255,0.1);
            border-radius: 15px;
            padding: 20px;
            backdrop-filter: blur(10px);
        }
        
        .camera-title {
            text-align: center;
            font-size: 1.2rem;
            margin-bottom: 15px;
            color: #ff6b6b;
        }
        
        .image-container {
            width: 100%;
            height: 300px;
            background: #000;
            border-radius: 10px;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            overflow: hidden;
        }
        
        .camera-image {
            max-width: 100%;
            max-height: 100%;
            object-fit: contain;
        }
        
        .loading {
            color: #00ff00;
            font-size: 1rem;
        }
        
        .controls {
            text-align: center;
            margin: 20px 0;
        }
        
        .btn {
            padding: 12px 24px;
            border: none;
            border-radius: 25px;
            font-size: 1rem;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 0 10px;
            background: linear-gradient(45deg, #4CAF50, #45a049);
            color: white;
        }
        
        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(76,175,80,0.3);
        }
        
        .stop-btn {
            background: linear-gradient(45deg, #f44336, #d32f2f);
        }
        
        .status {
            text-align: center;
            font-size: 1.1rem;
            margin: 15px 0;
            padding: 10px;
            background: rgba(0,0,0,0.3);
            border-radius: 10px;
        }
        
        .stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin-top: 20px;
        }
        
        .stat-box {
            background: rgba(0,0,0,0.3);
            padding: 15px;
            border-radius: 10px;
            text-align: center;
        }
        
        .stat-value {
            font-size: 1.5rem;
            font-weight: bold;
            color: #ff6b6b;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1 class="title">ğŸ”¥ ë™ì‹œ 4ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¬ë°</h1>
            <p>Project Aria ê³µì‹ Observer íŒ¨í„´ + deliver_queued_sensor_data</p>
        </div>
        
        <div class="cameras-grid">
            <div class="camera-box">
                <div class="camera-title">ğŸ“· RGB Camera</div>
                <div class="image-container">
                    <img id="rgbImage" class="camera-image" style="display: none;">
                    <div id="rgbLoading" class="loading">ëŒ€ê¸° ì¤‘...</div>
                </div>
            </div>
            
            <div class="camera-box">
                <div class="camera-title">ğŸ‘ï¸ SLAM Left</div>
                <div class="image-container">
                    <img id="slam-leftImage" class="camera-image" style="display: none;">
                    <div id="slam-leftLoading" class="loading">ëŒ€ê¸° ì¤‘...</div>
                </div>
            </div>
            
            <div class="camera-box">
                <div class="camera-title">ğŸ‘ï¸ SLAM Right</div>
                <div class="image-container">
                    <img id="slam-rightImage" class="camera-image" style="display: none;">
                    <div id="slam-rightLoading" class="loading">ëŒ€ê¸° ì¤‘...</div>
                </div>
            </div>
            
            <div class="camera-box">
                <div class="camera-title">ğŸ‘€ Eye Tracking</div>
                <div class="image-container">
                    <img id="eye-trackingImage" class="camera-image" style="display: none;">
                    <div id="eye-trackingLoading" class="loading">ëŒ€ê¸° ì¤‘...</div>
                </div>
            </div>
        </div>
        
        <div class="controls">
            <button class="btn" onclick="startConcurrentStreaming()">ğŸš€ ë™ì‹œ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘</button>
            <button class="btn stop-btn" onclick="stopStreaming()">ğŸ›‘ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€</button>
        </div>
        
        <div class="status" id="status">ì¤€ë¹„ë¨ - ê³µì‹ Observer íŒ¨í„´</div>
        
        <div class="stats">
            <div class="stat-box">
                <div class="stat-value" id="totalFrames">0</div>
                <div class="stat-label">ì´ í”„ë ˆì„</div>
            </div>
            <div class="stat-box">
                <div class="stat-value" id="activeCameras">0</div>
                <div class="stat-label">í™œì„± ì¹´ë©”ë¼</div>
            </div>
            <div class="stat-box">
                <div class="stat-value" id="fps">0</div>
                <div class="stat-label">FPS</div>
            </div>
            <div class="stat-box">
                <div class="stat-value" id="method">Observer</div>
                <div class="stat-label">ë°©ì‹</div>
            </div>
            <div class="stat-box">
                <div class="stat-value" id="replayCount">0</div>
                <div class="stat-label">ğŸ”„ ìˆœí™˜ ì¬ìƒ</div>
            </div>
            <div class="stat-box">
                <div class="stat-value" id="streamingTime">00:00</div>
                <div class="stat-label">â±ï¸ ì¬ìƒ ì‹œê°„</div>
            </div>
        </div>
    </div>

    <script>
        let streamingInterval = null;
        let frameCount = 0;
        let lastFrameTime = Date.now();
        let cameras = ['rgb', 'slam-left', 'slam-right', 'eye-tracking'];
        let streamingStartTime = null;
        let replayCount = 0;
        
        function startConcurrentStreaming() {
            fetch('/api/v1/aria-sessions/concurrent-streaming/start/', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' }
            })
            .then(response => response.json())
            .then(data => {
                console.log('ë™ì‹œ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘:', data);
                
                if (data.status === 'success') {
                    document.getElementById('status').textContent = 'ğŸ”¥ ë™ì‹œ 4ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™” (ìˆœí™˜ ì¬ìƒ)';
                    document.getElementById('method').textContent = 'ê³µì‹ Observer';
                    
                    // ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì‹œê°„ ê¸°ë¡
                    streamingStartTime = Date.now();
                    replayCount = 1;
                    document.getElementById('replayCount').textContent = replayCount;
                    
                    // ê°œë³„ ì¹´ë©”ë¼ë³„ ì´ë¯¸ì§€ ë¡œë”© ì‹œì‘
                    streamingInterval = setInterval(loadAllCameraFrames, 100); // 100msë§ˆë‹¤
                    loadAllCameraFrames();
                }
            })
            .catch(error => {
                console.error('ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì‹¤íŒ¨:', error);
            });
        }
        
        function loadAllCameraFrames() {
            cameras.forEach(camera => {
                loadCameraFrame(camera);
            });
        }
        
        function loadCameraFrame(cameraType) {
            fetch(`/api/v1/aria-sessions/concurrent-latest-frame/?camera=${cameraType}`)
            .then(response => {
                if (response.ok) {
                    const frameNumber = response.headers.get('X-Frame-Number');
                    const cameraTypeHeader = response.headers.get('X-Camera-Type');
                    
                    return response.blob();
                }
                throw new Error('No frame available');
            })
            .then(blob => {
                const url = URL.createObjectURL(blob);
                const imageEl = document.getElementById(cameraType + 'Image');
                const loadingEl = document.getElementById(cameraType + 'Loading');
                
                imageEl.src = url;
                imageEl.style.display = 'block';
                loadingEl.style.display = 'none';
                
                // ì´ì „ URL ì •ë¦¬
                if (imageEl.dataset.oldUrl) {
                    URL.revokeObjectURL(imageEl.dataset.oldUrl);
                }
                imageEl.dataset.oldUrl = url;
                
                frameCount++;
            })
            .catch(error => {
                // ì¡°ìš©íˆ ì²˜ë¦¬ (ë¡œê·¸ ìŠ¤íŒ¸ ë°©ì§€)
            });
        }
        
        function stopStreaming() {
            if (streamingInterval) {
                clearInterval(streamingInterval);
                streamingInterval = null;
            }
            
            fetch('/api/v1/aria-sessions/concurrent-streaming/stop/', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' }
            })
            .then(response => response.json())
            .then(data => {
                console.log('ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€:', data);
                
                document.getElementById('status').textContent = 'â¹ï¸ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€ë¨';
                
                cameras.forEach(camera => {
                    document.getElementById(camera + 'Image').style.display = 'none';
                    document.getElementById(camera + 'Loading').style.display = 'block';
                    document.getElementById(camera + 'Loading').textContent = 'ëŒ€ê¸° ì¤‘...';
                });
            });
        }
        
        // í†µê³„ ì—…ë°ì´íŠ¸
        setInterval(() => {
            const now = Date.now();
            const timeDiff = now - lastFrameTime;
            
            if (timeDiff > 1000) {
                const fps = Math.round(frameCount * 1000 / timeDiff);
                document.getElementById('fps').textContent = fps;
                document.getElementById('totalFrames').textContent = frameCount;
                
                // í™œì„± ì¹´ë©”ë¼ ìˆ˜ ê³„ì‚°
                let activeCameras = 0;
                cameras.forEach(camera => {
                    const imageEl = document.getElementById(camera + 'Image');
                    if (imageEl.style.display === 'block') {
                        activeCameras++;
                    }
                });
                document.getElementById('activeCameras').textContent = activeCameras;
                
                // ìŠ¤íŠ¸ë¦¬ë° ì‹œê°„ ì—…ë°ì´íŠ¸
                if (streamingStartTime) {
                    const elapsed = Math.floor((now - streamingStartTime) / 1000);
                    const minutes = Math.floor(elapsed / 60);
                    const seconds = elapsed % 60;
                    document.getElementById('streamingTime').textContent = 
                        `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
                }
                
                // ìˆœí™˜ ì¬ìƒ ê°ì§€ (FPSê°€ ê°‘ìê¸° ë†’ì•„ì§€ë©´ ìƒˆ ì‚¬ì´í´ ì‹œì‘)
                if (fps > 20 && frameCount > 50) {
                    const currentReplay = Math.floor((now - streamingStartTime) / 30000); // ëŒ€ëµ 30ì´ˆë§ˆë‹¤ ì‚¬ì´í´
                    if (currentReplay > replayCount - 1) {
                        replayCount = currentReplay + 1;
                        document.getElementById('replayCount').textContent = replayCount;
                        console.log(`ğŸ”„ ìˆœí™˜ ì¬ìƒ ${replayCount}íšŒì°¨ ê°ì§€`);
                    }
                }
                
                lastFrameTime = now;
                frameCount = 0;
            }
        }, 1000);
    </script>
</body>
</html>
        '''
        
        return HttpResponse(html_template)